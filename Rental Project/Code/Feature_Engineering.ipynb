{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d592655-d0c3-49fb-93f0-52a84a3e8860",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2076fd3f-2027-4ec9-95c3-a3d823ffc7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import logging \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from geopy.geocoders import Nominatim, GoogleV3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a96a827-b3a2-435d-9bbd-c2e6b108fb55",
   "metadata": {},
   "source": [
    "### Read & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4137b2-3417-47a9-bc10-4b8f075c8d91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Rental_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a193bd-f78d-49a6-ab71-d0c4f9e5dd75",
   "metadata": {},
   "source": [
    "### Extracting Full Address, Latitude, Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9776e544-b5bf-4bcd-a2c2-f4cfc13a14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace elements in the \"address\" column before run the geolocator\n",
    "df['address'] = df['address'].str.replace(r'\\bLor\\b', 'Lorong', regex=True)\n",
    "df['address'] = df['address'].str.replace(r'\\bNth\\b', 'North', regex=True)\n",
    "df['address'] = df['address'].str.replace(r'\\bBt\\b', 'Bukit', regex=True)\n",
    "df['address'] = df['address'].str.replace(r'\\bUpp\\b', 'Upper', regex=True)\n",
    "df['address'] = df['address'].str.replace(r'\\bTg\\b', 'Tanjong', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba6b13-bfe4-4bbd-bc1f-2be9a051992a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize Nominatim geocoder \n",
    "geolocator = Nominatim(user_agent=\"james\", timeout=10)\n",
    "\n",
    "# Function to get full address, latitude, longitude\n",
    "def geocode_and_get_details(address):\n",
    "    location = geolocator.geocode(address + \",Singapore\")\n",
    "    if location:\n",
    "        lat, lon = location.latitude, location.longitude\n",
    "        full_address = location.address\n",
    "        print(f\"Geocoded: {address} -> Latitude: {lat}, Longitude: {lon}\")\n",
    "        return full_address, lat, lon\n",
    "    else:\n",
    "        logging.warning(f\"Failed to geocode: {address}\")\n",
    "        return None, None, None  # Return defaults if geocoding fails\n",
    "\n",
    "# Apply the combined function to the DataFrame\n",
    "df['full_address'], df['latitude'], df['longitude'] = zip(*df['address'].apply(geocode_and_get_details))\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cff295-8633-4e24-820d-6e7fa9fba658",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Geocoding process took {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3908c749-fadf-458e-9425-e9f9b99b5377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Google Geocoder\n",
    "api_key = 'AIzaSyBvuUbJevwEF4sQl1jKd78C1MJSk89PxCA'\n",
    "google_geolocator = GoogleV3(api_key=api_key)\n",
    "\n",
    "# Create a function to geocode addresses using Google Geocoding API\n",
    "def geocode_with_google(address):\n",
    "    try:\n",
    "        location_g = google_geolocator.geocode(address + \", Singapore\")\n",
    "        if location_g:\n",
    "            lat, lon = location_g.latitude, location_g.longitude\n",
    "            full_address = location_g.address\n",
    "            print(f\"Geocoded (Google): {address} -> Latitude: {lat}, Longitude: {lon}\")\n",
    "            return full_address, lat, lon\n",
    "        else:\n",
    "            print(f\"Google Geocoding API couldn't find a result for: {address}\")\n",
    "            return None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Google Geocoding: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "remaining_df = df.loc[df['full_address'].isnull()]\n",
    "# Apply the Google Geocoding function to the remaining DataFrame\n",
    "remaining_df['full_address_google'], remaining_df['latitude_google'], remaining_df['longitude_google'] = zip(*remaining_df['address'].apply(geocode_with_google))\n",
    "\n",
    "# Define a condition for rows where 'full_address' is null\n",
    "condition = df['full_address'].isnull()\n",
    "\n",
    "# Assign the values from remaining_df to df based on the condition\n",
    "df.loc[condition, 'latitude'] = remaining_df['latitude_google'].values\n",
    "df.loc[condition, 'longitude'] = remaining_df['longitude_google'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f8bfb-facd-45b2-8843-aa01a382f593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean the full_address_google by removing the postal code\n",
    "remaining_df['full_address_google'] = remaining_df['full_address_google'].str.split(',').str[0].str.strip()\n",
    "\n",
    "# Apply the geocode_and_get_details function to the remaining_df\n",
    "geocoded_results = remaining_df['full_address_google'].apply(geocode_and_get_details)\n",
    "\n",
    "# Extract the full address part from tuples in 'geocoded_results'\n",
    "geocoded_addresses = geocoded_results.apply(lambda x: x[0] if isinstance(x, tuple) else x)\n",
    "\n",
    "# Update the DataFrame using .loc with the condition\n",
    "df.loc[condition, 'full_address'] = geocoded_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913ca52-7e31-4298-ab31-59f996b656ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Geocoding for remaining address\n",
    "property_full_address = pd.read_csv('address_list.csv')\n",
    "\n",
    "# Define a custom function to replace None & Singapore with values from other DataFrame\n",
    "def replace_full_address(row):\n",
    "    if row['full_address'] is None or row['full_address'].lower() == 'singapore' or row['full_address'].lower() == 'singapore, central, 178957, singapore' :\n",
    "        matching_row = property_full_address[property_full_address['address'] == row['address']]\n",
    "        if not matching_row.empty:\n",
    "            return matching_row.iloc[0]['geocoded_address']\n",
    "    return row['full_address']\n",
    "\n",
    "# Apply the custom function to update 'full_address' column\n",
    "df['full_address'] = df.apply(replace_full_address, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1baed4e-f6bd-407d-a0f6-6afd1d962bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geocoding for address with 'Woodlands Drive'\n",
    "\n",
    "# Define a function to update full_address\n",
    "def update_full_address(row):\n",
    "    if 'Woodlands Drive' in row['address'] and row['full_address'] == None:\n",
    "        return row['address'] + ', Woodlands, Northwest, 730888, Singapore'\n",
    "    return row['full_address']\n",
    "\n",
    "# Apply the update_full_address function to the DataFrame\n",
    "df['full_address'] = df.apply(update_full_address, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52656ba3-a36e-4313-bf0a-ecdc8451bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all \"Singapore\" \n",
    "df['full_address'] = df['full_address'].apply(lambda x: ', '.join([str(part).strip() for part in str(x).split(', ') if part != 'Singapore']))\n",
    "\n",
    "# Add ', Singapore' to the end of every row\n",
    "df['full_address'] = df['full_address'] + ', Singapore'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f57ef1-f695-4e69-a30b-51e49987b85d",
   "metadata": {},
   "source": [
    "### Extracting Planning Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0dec06-8d93-47bc-8e50-6148790a344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "# This file is to map planning area based on subzone\n",
    "subzone_planning_area = pd.read_csv('planning_area_subzone_list.csv')\n",
    "\n",
    "# Create a dictionary mapping subzones to planning areas\n",
    "subzone_to_planning_area = dict(zip(subzone_planning_area['Subzone'], subzone_planning_area['Planning_area']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef79d64-c8d8-4d6f-917d-da65eb62328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of planning areas and regions\n",
    "planning_areas = [\n",
    "    \"Ang Mo Kio\",\"Bedok\",\"Bishan\",\"Boon Lay\",\"Bukit Batok\",\"Bukit Merah\",\"Bukit Panjang\",\"Bukit Timah\",\"Central Water Catchment\",\n",
    "    \"Changi\",\"Changi Bay\",\"Choa Chu Kang\",\"Clementi\",\"Downtown Core\",\"Geylang\",\"Hougang\",\"Jurong East\",\"Jurong West\",\"Kallang\",\n",
    "    \"Lim Chu Kang\",\"Mandai\",\"Marina East\",\"Marina South\",\"Marine Parade\",\"Museum\",\"Newton\",\"North-Eastern Islands\",\"Novena\",\n",
    "    \"Orchard\",\"Outram\",\"Pasir Ris\",\"Paya Lebar\",\"Pioneer\",\"Punggol\",\"Queenstown\",\"River Valley\",\"Rochor\",\"Seletar\",\"Sembawang\",\n",
    "    \"Seng Kang\",\"Serangoon\",\"Simpang\",\"Singapore River\",\"Southern Islands\",\"Straits View\",\"Sungei Kadut\",\"Tampines\",\"Tanglin\",\n",
    "    \"Tengah\",\"Toa Payoh\",\"Tuas\",\"Western Islands\",\"Western Water Catchment\",\"Woodlands\",\"Yishun\"\n",
    "]\n",
    "\n",
    "\n",
    "# Create empty columns for planning_area and region\n",
    "df['planning_area'] = \"\"\n",
    "\n",
    "# Define a function to extract planning_area and region\n",
    "def extract_planning_area_and_region(address):\n",
    "    # Split the address by \",\"\n",
    "    address_parts = address.split(',')\n",
    "    \n",
    "    # Initialize variables to store planning area and region\n",
    "    planning_area = \"\"\n",
    "    \n",
    "    # Iterate through the address parts\n",
    "    for part in address_parts:\n",
    "        part = part.strip()  # Remove leading/trailing spaces\n",
    "        \n",
    "        if part in planning_areas:\n",
    "            planning_area = part\n",
    "            break  # Exit the loop if planning area is found\n",
    "\n",
    "    # If no planning area found, check for subzone and assign planning area based on the subzone\n",
    "    if not planning_area:\n",
    "        for part in address_parts:\n",
    "            part = part.strip()\n",
    "            if part in subzone_to_planning_area:\n",
    "                planning_area = subzone_to_planning_area[part]\n",
    "                break  # Exit the loop if subzone is found\n",
    "\n",
    "    return planning_area\n",
    "\n",
    "# Apply the function to extract values and populate the DataFrame\n",
    "df['planning_area'] = df['full_address'].apply(extract_planning_area_and_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f06d7cb-722a-41d0-8e1d-f19137fd115b",
   "metadata": {},
   "source": [
    "### Extracting Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589bc573-ca48-4840-b24d-a83713cc6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping planning areas to regions\n",
    "planning_area_to_region = {\n",
    "    'Ang Mo Kio': 'North-East',\n",
    "    'Bedok': 'East',\n",
    "    'Bishan': 'Central',\n",
    "    'Boon Lay': 'West',\n",
    "    'Bukit Batok': 'West',\n",
    "    'Bukit Merah': 'Central',\n",
    "    'Bukit Panjang': 'West',\n",
    "    'Bukit Timah': 'Central',\n",
    "    'Central Water Catchment': 'North',\n",
    "    'Changi': 'East',\n",
    "    'Changi Bay': 'East',\n",
    "    'Choa Chu Kang': 'West',\n",
    "    'Clementi': 'West',\n",
    "    'Downtown Core': 'Central',\n",
    "    'Geylang': 'Central',\n",
    "    'Hougang': 'North-East',\n",
    "    'Jurong East': 'West',\n",
    "    'Jurong West': 'West',\n",
    "    'Kallang': 'Central',\n",
    "    'Lim Chu Kang': 'North',\n",
    "    'Mandai': 'North',\n",
    "    'Marina East': 'Central',\n",
    "    'Marina South': 'Central',\n",
    "    'Marine Parade': 'Central',\n",
    "    'Museum': 'Central',\n",
    "    'Newton': 'Central',\n",
    "    'North-Eastern Islands': 'North-East',\n",
    "    'Novena': 'Central',\n",
    "    'Orchard': 'Central',\n",
    "    'Outram': 'Central',\n",
    "    'Pasir Ris': 'East',\n",
    "    'Paya Lebar': 'East',\n",
    "    'Pioneer': 'West',\n",
    "    'Punggol': 'North-East',\n",
    "    'Queenstown': 'Central',\n",
    "    'River Valley': 'Central',\n",
    "    'Rochor': 'Central',\n",
    "    'Seletar': 'North-East',\n",
    "    'Sembawang': 'North',\n",
    "    'Seng Kang': 'North-East',\n",
    "    'Serangoon': 'North-East',\n",
    "    'Simpang': 'North',\n",
    "    'Singapore River': 'Central',\n",
    "    'Southern Islands': 'Central',\n",
    "    'Straits View': 'Central',\n",
    "    'Sungei Kadut': 'North',\n",
    "    'Tampines': 'East',\n",
    "    'Tanglin': 'Central',\n",
    "    'Tengah': 'West',\n",
    "    'Toa Payoh': 'Central',\n",
    "    'Tuas': 'West',\n",
    "    'Western Islands': 'West',\n",
    "    'Western Water Catchment': 'West',\n",
    "    'Woodlands': 'North',\n",
    "    'Yishun': 'North'\n",
    "}\n",
    "# Assign regions based on the planning_area column\n",
    "df['region'] = df['planning_area'].map(planning_area_to_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cecf4d4-cab8-47f5-92d4-1307550cb7c8",
   "metadata": {},
   "source": [
    "### Extracting Nearest MRT Station, Distance & Time to the nearest station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0ad098-ddf1-4459-9991-0e7ad6e5ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrt = pd.read_csv('MRT Stations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf947fe-8bc9-494e-82e9-431d370b4027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Haversine distance between two sets of coordinates\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Radius of the Earth in kilometers\n",
    "    radius = 6371.0\n",
    "    \n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    distance = radius * c\n",
    "    \n",
    "    return distance\n",
    "\n",
    "# Function to find the nearest MRT station and its Haversine distance\n",
    "def find_nearest_mrt(row):\n",
    "    address_lat = row['latitude']\n",
    "    address_lon = row['longitude']\n",
    "    \n",
    "    min_distance = float('inf')\n",
    "    nearest_station = ''\n",
    "    \n",
    "    for _, mrt_row in mrt.iterrows():\n",
    "        mrt_lat = mrt_row['latitude']\n",
    "        mrt_lon = mrt_row['longitude']\n",
    "        \n",
    "        distance = haversine(address_lat, address_lon, mrt_lat, mrt_lon)\n",
    "        \n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            nearest_station = mrt_row['STN_NAME']\n",
    "    \n",
    "    return nearest_station, min_distance\n",
    "\n",
    "# Apply the function to your 'df' DataFrame\n",
    "df[['Nearest MRT Station', 'Distance to Nearest MRT']] = df.apply(find_nearest_mrt, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7972d4-6267-4731-9dc2-ebc82c0064ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define walking speed in km/h\n",
    "walking_speed_kmph = 5\n",
    "\n",
    "# Function to calculate walking time\n",
    "def calculate_walking_time(row):\n",
    "    # Get the walking distance (in kilometers)\n",
    "    walking_distance_km = row['Distance to Nearest MRT']\n",
    "\n",
    "    # Calculate walking time (in hours)\n",
    "    walking_time_hours = walking_distance_km / walking_speed_kmph\n",
    "\n",
    "    # Convert to minutes if needed\n",
    "    walking_time_minutes = walking_time_hours * 60\n",
    "\n",
    "    return walking_time_minutes\n",
    "\n",
    "# Apply the function to your 'df' DataFrame and create a new column for walking time\n",
    "df['Walking Time to Nearest MRT (minutes)'] = df.apply(calculate_walking_time, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bf24a5-e83f-4cac-91b1-b4585daea44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the join based on the \"Nearest MRT Station\" column\n",
    "df = df.merge(mrt[['STN_NAME', 'latitude', 'longitude']], left_on='Nearest MRT Station', right_on='STN_NAME', how='left')\n",
    "\n",
    "# Drop the duplicate \"STN_NAME\" column if needed\n",
    "df.drop(columns=['STN_NAME','nearest_mrt','time_to_nearest_mrt'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6eac94-0663-4023-8cc8-ea512cea95d1",
   "metadata": {},
   "source": [
    "### Final Cleanup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ec318-9349-4bbc-b2a0-fcf8301a50ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a dictionary to map old column names to new column names\n",
    "column_mapping = {'latitude_x': 'latitude', 'longitude_x': 'longitude', 'latitude_y': 'latitude_mrt'\n",
    "                  ,'longitude_y':'longitude_mrt','Distance to Nearest MRT':'Distance_to_Nearest_MRT_km'\n",
    "                  ,'Walking Time to Nearest MRT (minutes)':'Walking_Time_to_Nearest_MRT_min'\n",
    "                  ,'room_size':'room_size_sqft','Nearest MRT Station':'Nearest_MRT_Station'}\n",
    "\n",
    "# Use the .rename() method to rename columns\n",
    "df = df.rename(columns=column_mapping)\n",
    "\n",
    "# Define the desired order of columns\n",
    "desired_order = ['address', 'full_address', 'latitude', 'longitude', 'planning_area', 'region', 'Nearest_MRT_Station'\n",
    "                 , 'latitude_mrt', 'longitude_mrt', 'Distance_to_Nearest_MRT_km', 'Walking_Time_to_Nearest_MRT_min'\n",
    "                 , 'price', 'unit_type', 'room_type', 'room_size_sqft', 'status', 'updated_date', 'link']\n",
    "\n",
    "# Select the columns in the desired order\n",
    "df = df[desired_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078cc5b-34ab-4017-9c8e-553ccf177aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to the CSV file\n",
    "df.to_csv('Rental_data_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
